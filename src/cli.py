#!/usr/bin/env python3
"""
whisper-realtime CLI
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°æ–‡å­—èµ·ã“ã—ã®ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
"""

import signal
import sys
import threading
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Optional

import click
import numpy as np
from rich.console import Console, Group
from rich.live import Live
from rich.panel import Panel
from rich.table import Table
from rich.text import Text
from rich.layout import Layout
from rich.style import Style

from .audio_capture import AudioCapture, AudioConfig, AudioSource, VADFilter
from .diarization import DiarizationManager
from .whisper_engine import (
    MODEL_PROFILES,
    StreamingWhisperEngine,
    WhisperConfig,
    WhisperEngine,
    WhisperModel,
)

console = Console()


@dataclass
class ConversationEntry:
    """ä¼šè©±ã‚¨ãƒ³ãƒˆãƒªãƒ¼"""
    speaker: str
    text: str
    timestamp: float


# è©±è€…ã”ã¨ã®è‰²
SPEAKER_COLORS = [
    "cyan",
    "green",
    "yellow",
    "magenta",
    "blue",
    "red",
]


class RealtimeDisplay:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼ˆã‚¹ã‚¿ãƒƒã‚¯è¡¨ç¤ºå¯¾å¿œï¼‰"""

    def __init__(self, show_speaker: bool = False, max_history: int = 50):
        self.show_speaker = show_speaker
        self.max_history = max_history
        self.partial_text = ""
        self.current_speaker = ""
        self.conversation_history: list[ConversationEntry] = []
        self._speaker_colors: dict[str, str] = {}
        self._color_index = 0
        self._lock = threading.Lock()

    def _get_speaker_color(self, speaker: str) -> str:
        """è©±è€…ã®è‰²ã‚’å–å¾—ï¼ˆãªã‘ã‚Œã°å‰²ã‚Šå½“ã¦ï¼‰"""
        if speaker not in self._speaker_colors:
            self._speaker_colors[speaker] = SPEAKER_COLORS[self._color_index % len(SPEAKER_COLORS)]
            self._color_index += 1
        return self._speaker_colors[speaker]

    def update(self, text: str, is_partial: bool = False, speaker: str = ""):
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›´æ–°"""
        with self._lock:
            if speaker:
                self.current_speaker = speaker

            if is_partial:
                self.partial_text = text
            else:
                # ç¢ºå®šãƒ†ã‚­ã‚¹ãƒˆã‚’ä¼šè©±å±¥æ­´ã«è¿½åŠ 
                final_text = self.partial_text if self.partial_text else text
                if final_text:
                    entry = ConversationEntry(
                        speaker=self.current_speaker or "è©±è€…",
                        text=final_text,
                        timestamp=time.time(),
                    )
                    self.conversation_history.append(entry)

                    # å±¥æ­´ã®ä¸Šé™ã‚’è¶…ãˆãŸã‚‰å¤ã„ã‚‚ã®ã‚’å‰Šé™¤
                    if len(self.conversation_history) > self.max_history:
                        self.conversation_history = self.conversation_history[-self.max_history:]

                self.partial_text = ""

                # æ–°ã—ã„ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Œã°è¿½åŠ 
                if text and text != final_text:
                    entry = ConversationEntry(
                        speaker=self.current_speaker or "è©±è€…",
                        text=text,
                        timestamp=time.time(),
                    )
                    self.conversation_history.append(entry)

    def _render_history(self) -> Panel:
        """ä¼šè©±å±¥æ­´ãƒ‘ãƒãƒ«ã‚’ç”Ÿæˆ"""
        content = Text()

        if not self.conversation_history:
            content.append("(ä¼šè©±å±¥æ­´ãªã—)", style="dim")
        else:
            # æœ€æ–°ã®ä¼šè©±ã‚’è¡¨ç¤º
            display_entries = self.conversation_history[-30:]  # æœ€æ–°30ä»¶

            for entry in display_entries:
                if self.show_speaker:
                    color = self._get_speaker_color(entry.speaker)
                    content.append(f"[{entry.speaker}] ", style=f"bold {color}")
                content.append(f"{entry.text}\n")

        return Panel(
            content,
            title="[bold blue]ä¼šè©±å±¥æ­´[/bold blue]",
            border_style="blue",
            padding=(0, 1),
        )

    def _render_live(self) -> Panel:
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ãƒ‘ãƒãƒ«ã‚’ç”Ÿæˆ"""
        content = Text()

        if self.partial_text:
            if self.show_speaker and self.current_speaker:
                color = self._get_speaker_color(self.current_speaker)
                content.append(f"[{self.current_speaker}] ", style=f"bold {color}")
            content.append(self.partial_text, style="italic")
        else:
            content.append("ğŸ¤ éŸ³å£°ã‚’å¾…æ©Ÿä¸­...", style="dim")

        return Panel(
            content,
            title="[bold green]ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ [/bold green]",
            subtitle="[dim]Ctrl+C ã§çµ‚äº†[/dim]",
            border_style="green",
            padding=(0, 1),
        )

    def render(self) -> Group:
        """è¡¨ç¤ºç”¨ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ç”Ÿæˆï¼ˆå±¥æ­´ + ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼‰"""
        with self._lock:
            return Group(
                self._render_history(),
                self._render_live(),
            )

    def get_full_text(self) -> str:
        """å…¨ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—"""
        with self._lock:
            lines = []
            for entry in self.conversation_history:
                if self.show_speaker:
                    lines.append(f"[{entry.speaker}] {entry.text}")
                else:
                    lines.append(entry.text)
            if self.partial_text:
                lines.append(self.partial_text)
            return "\n".join(lines)


def list_audio_devices():
    """ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§ã‚’è¡¨ç¤º"""
    devices = AudioCapture.list_devices()

    table = Table(title="åˆ©ç”¨å¯èƒ½ãªã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹")
    table.add_column("ID", style="cyan")
    table.add_column("åå‰", style="green")
    table.add_column("ãƒãƒ£ãƒ³ãƒãƒ«", style="yellow")
    table.add_column("ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ", style="magenta")

    for device in devices:
        table.add_row(
            str(device["id"]),
            device["name"],
            str(device["channels"]),
            "â˜…" if device["is_default"] else "",
        )

    console.print(table)

    # BlackHoleæ¤œå‡º
    blackhole_id = AudioCapture.find_blackhole_device()
    if blackhole_id is not None:
        console.print(f"\n[green]BlackHoleæ¤œå‡º: ID {blackhole_id}[/green]")
        console.print("ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ãŒåˆ©ç”¨å¯èƒ½ã§ã™")
    else:
        console.print("\n[yellow]BlackHoleãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“[/yellow]")
        console.print("ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã™ã‚‹ã«ã¯: brew install blackhole-2ch")


def list_models(models_path: Path):
    """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º"""
    table = Table(title="åˆ©ç”¨å¯èƒ½ãªWhisperãƒ¢ãƒ‡ãƒ«")
    table.add_column("ãƒ¢ãƒ‡ãƒ«", style="cyan")
    table.add_column("ã‚µã‚¤ã‚º", style="yellow")
    table.add_column("ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", style="green")
    table.add_column("æ¨å¥¨ç”¨é€”", style="magenta")

    model_info = {
        "tiny": ("~75MB", "æœ€é€Ÿã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‘ã‘"),
        "tiny.en": ("~75MB", "è‹±èªã®ã¿ã€æœ€é€Ÿ"),
        "base": ("~142MB", "ãƒãƒ©ãƒ³ã‚¹å‹"),
        "base.en": ("~142MB", "è‹±èªã®ã¿ã€ãƒãƒ©ãƒ³ã‚¹"),
        "small": ("~466MB", "é«˜ç²¾åº¦"),
        "small.en": ("~466MB", "è‹±èªã®ã¿ã€é«˜ç²¾åº¦"),
        "medium": ("~1.5GB", "ã‚ˆã‚Šé«˜ç²¾åº¦"),
        "medium.en": ("~1.5GB", "è‹±èªã®ã¿"),
        "large-v1": ("~2.9GB", "æœ€é«˜ç²¾åº¦"),
        "large-v2": ("~2.9GB", "æœ€é«˜ç²¾åº¦v2"),
        "large-v3": ("~2.9GB", "æœ€é«˜ç²¾åº¦v3"),
        "large-v3-turbo": ("~1.5GB", "é«˜ç²¾åº¦+é«˜é€Ÿ"),
    }

    for model in WhisperModel:
        model_file = models_path / f"ggml-{model.value}.bin"
        exists = model_file.exists()
        size, usage = model_info.get(model.value, ("?", "?"))

        table.add_row(
            model.value,
            size,
            "[green]ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆ[/green]" if exists else "[dim]æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«[/dim]",
            usage,
        )

    console.print(table)
    console.print("\nãƒ¢ãƒ‡ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰:")
    console.print("  ./setup.sh --model <model-name>")


@click.group()
def cli():
    """whisper-realtime: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°æ–‡å­—èµ·ã“ã—"""
    pass


@cli.command()
def devices():
    """ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§ã‚’è¡¨ç¤º"""
    list_audio_devices()


@cli.command()
@click.option("--device", "-d", type=int, help="ãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹ID")
@click.option("--duration", type=int, default=5, help="ãƒ†ã‚¹ãƒˆæ™‚é–“ï¼ˆç§’ï¼‰")
def test_mic(device: Optional[int], duration: int):
    """ãƒã‚¤ã‚¯å…¥åŠ›ã‚’ãƒ†ã‚¹ãƒˆï¼ˆéŸ³å£°ãƒ¬ãƒ™ãƒ«ã‚’è¡¨ç¤ºï¼‰"""
    from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn

    audio_config = AudioConfig(sample_rate=16000, chunk_duration=0.1)

    console.print(f"[bold]ãƒã‚¤ã‚¯ãƒ†ã‚¹ãƒˆ[/bold] ({duration}ç§’é–“)")
    console.print("è©±ã—ã‹ã‘ã¦ãã ã•ã„...\n")

    try:
        audio_capture = AudioCapture(
            config=audio_config,
            source=AudioSource.MICROPHONE,
            device_id=device,
        )
    except Exception as e:
        console.print(f"[red]ã‚¨ãƒ©ãƒ¼: ãƒã‚¤ã‚¯ã‚’é–‹ã‘ã¾ã›ã‚“: {e}[/red]")
        console.print("\n[yellow]ãƒ’ãƒ³ãƒˆ:[/yellow]")
        console.print("  1. ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®š > ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ > ãƒã‚¤ã‚¯")
        console.print("  2. ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã‚¢ãƒ—ãƒªã«ãƒã‚¤ã‚¯ã‚¢ã‚¯ã‚»ã‚¹ã‚’è¨±å¯")
        return

    start_time = time.time()
    max_level = 0

    with audio_capture:
        while time.time() - start_time < duration:
            audio = audio_capture.get_audio(timeout=0.2)
            if audio is not None and len(audio) > 0:
                # RMSãƒ¬ãƒ™ãƒ«ã‚’è¨ˆç®—
                rms = np.sqrt(np.mean(audio ** 2))
                level = min(int(rms * 500), 50)  # 0-50ã®ãƒãƒ¼
                max_level = max(max_level, level)

                # ãƒ¬ãƒ™ãƒ«ãƒ¡ãƒ¼ã‚¿ãƒ¼è¡¨ç¤º
                bar = "â–ˆ" * level + "â–‘" * (50 - level)
                console.print(f"\r[green]{bar}[/green] {rms:.4f}", end="")

    console.print("\n")

    if max_level > 5:
        console.print(f"[green]âœ“ ãƒã‚¤ã‚¯ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™[/green] (æœ€å¤§ãƒ¬ãƒ™ãƒ«: {max_level})")
    elif max_level > 0:
        console.print(f"[yellow]â–³ éŸ³å£°ãƒ¬ãƒ™ãƒ«ãŒä½ã„ã§ã™[/yellow] (æœ€å¤§ãƒ¬ãƒ™ãƒ«: {max_level})")
        console.print("  ãƒã‚¤ã‚¯ã«è¿‘ã¥ã„ã¦è©±ã—ã¦ã¿ã¦ãã ã•ã„")
    else:
        console.print("[red]âœ— éŸ³å£°ãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ[/red]")
        console.print("\n[yellow]ç¢ºèªäº‹é …:[/yellow]")
        console.print("  1. ãƒã‚¤ã‚¯ãŒãƒŸãƒ¥ãƒ¼ãƒˆã«ãªã£ã¦ã„ãªã„ã‹ç¢ºèª")
        console.print("  2. ã‚·ã‚¹ãƒ†ãƒ ç’°å¢ƒè¨­å®šã§ãƒã‚¤ã‚¯å…¥åŠ›ã‚’ç¢ºèª")
        console.print("  3. uv run whisper-realtime devices ã§æ­£ã—ã„ãƒ‡ãƒã‚¤ã‚¹ã‚’ç¢ºèª")


@cli.command()
@click.option("--path", type=click.Path(exists=True), help="ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
def models(path: Optional[str]):
    """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º"""
    models_path = Path(path) if path else Path(__file__).parent.parent / "models"
    list_models(models_path)


@cli.command()
@click.option(
    "--source", "-s",
    type=click.Choice(["mic", "system", "both"]),
    default="mic",
    help="éŸ³å£°å…¥åŠ›ã‚½ãƒ¼ã‚¹",
)
@click.option(
    "--model", "-m",
    type=click.Choice([m.value for m in WhisperModel]),
    default="base",
    help="ä½¿ç”¨ã™ã‚‹Whisperãƒ¢ãƒ‡ãƒ«",
)
@click.option(
    "--profile", "-p",
    type=click.Choice(list(MODEL_PROFILES.keys())),
    help="ãƒ¢ãƒ‡ãƒ«ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ« (realtime/balanced/quality/best)",
)
@click.option(
    "--language", "-l",
    default="ja",
    help="è¨€èªã‚³ãƒ¼ãƒ‰ (ja, en, auto)",
)
@click.option(
    "--device", "-d",
    type=int,
    help="ãƒã‚¤ã‚¯ãƒ‡ãƒã‚¤ã‚¹ID",
)
@click.option(
    "--system-device",
    type=int,
    help="ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ãƒ‡ãƒã‚¤ã‚¹ID (BlackHole)",
)
@click.option(
    "--speaker/--no-speaker",
    default=False,
    help="è©±è€…åˆ†é›¢ã‚’æœ‰åŠ¹åŒ–",
)
@click.option(
    "--translate/--no-translate",
    default=False,
    help="è‹±èªã«ç¿»è¨³",
)
@click.option(
    "--output", "-o",
    type=click.Path(),
    help="å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹",
)
@click.option(
    "--step",
    type=int,
    default=500,
    help="å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ— (ms)",
)
@click.option(
    "--length",
    type=int,
    default=3000,
    help="å‡¦ç†çª“ã®é•·ã• (ms) - çŸ­ã„ã»ã©åå¿œãŒæ—©ã„",
)
@click.option(
    "--vad/--no-vad",
    default=True,
    help="éŸ³å£°åŒºé–“æ¤œå‡ºã‚’ä½¿ç”¨",
)
@click.option(
    "--debug/--no-debug",
    default=False,
    help="ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼ˆå‡¦ç†çŠ¶æ³ã‚’è¡¨ç¤ºï¼‰",
)
def start(
    source: str,
    model: str,
    profile: Optional[str],
    language: str,
    device: Optional[int],
    system_device: Optional[int],
    speaker: bool,
    translate: bool,
    output: Optional[str],
    step: int,
    length: int,
    vad: bool,
    debug: bool,
):
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—ã‚’é–‹å§‹"""
    import os

    # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã€ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®š
    if debug:
        os.environ["WHISPER_DEBUG"] = "1"

    # ãƒ¢ãƒ‡ãƒ«è¨­å®š
    if profile:
        whisper_model = MODEL_PROFILES[profile]
    else:
        whisper_model = WhisperModel(model)

    # è¨­å®šè¡¨ç¤º
    console.print(Panel.fit(
        f"[bold]è¨­å®š[/bold]\n"
        f"ãƒ¢ãƒ‡ãƒ«: {whisper_model.value}\n"
        f"è¨€èª: {language}\n"
        f"ã‚½ãƒ¼ã‚¹: {source}\n"
        f"è©±è€…åˆ†é›¢: {'æœ‰åŠ¹' if speaker else 'ç„¡åŠ¹'}\n"
        f"å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—: {step}ms\n"
        f"å‡¦ç†çª“: {length}ms",
        title="whisper-realtime",
        border_style="blue",
    ))

    # éŸ³å£°ã‚½ãƒ¼ã‚¹è¨­å®š
    audio_source = {
        "mic": AudioSource.MICROPHONE,
        "system": AudioSource.SYSTEM,
        "both": AudioSource.BOTH,
    }[source]

    # Whisperè¨­å®š
    whisper_config = WhisperConfig(
        model=whisper_model,
        language=language,
        translate=translate,
        step_ms=step,
        length_ms=length,
    )

    # è©±è€…åˆ†é›¢ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
    diarizer = DiarizationManager(use_pyannote=False) if speaker else None

    # è¡¨ç¤ºãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
    display = RealtimeDisplay(show_speaker=speaker)

    # VADãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    vad_filter = VADFilter() if vad else None

    # éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£è¨­å®š
    audio_config = AudioConfig(
        sample_rate=16000,
        chunk_duration=step / 1000,
    )

    # çµ‚äº†ãƒ•ãƒ©ã‚°
    running = True

    def signal_handler(sig, frame):
        nonlocal running
        running = False
        console.print("\n[yellow]çµ‚äº†ä¸­...[/yellow]")

    signal.signal(signal.SIGINT, signal_handler)

    # Whisperã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
    try:
        engine = WhisperEngine(whisper_config)
    except FileNotFoundError as e:
        console.print(f"[red]ã‚¨ãƒ©ãƒ¼: {e}[/red]")
        console.print("\n[yellow]setup.sh ã‚’å®Ÿè¡Œã—ã¦ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãã ã•ã„[/yellow]")
        sys.exit(1)

    # çµæœã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
    def on_result(result):
        text = result.text
        is_partial = not result.is_final

        if speaker and diarizer:
            current_speaker = diarizer._current_speaker
        else:
            current_speaker = ""

        display.update(text, is_partial=is_partial, speaker=current_speaker)

    engine.set_callback(on_result)

    # éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£é–‹å§‹
    try:
        audio_capture = AudioCapture(
            config=audio_config,
            source=audio_source,
            device_id=device,
            system_device_id=system_device,
        )
    except Exception as e:
        console.print(f"[red]éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ã‚¨ãƒ©ãƒ¼: {e}[/red]")
        sys.exit(1)

    console.print("\n[green]éŒ²éŸ³é–‹å§‹... (Ctrl+C ã§çµ‚äº†)[/green]")
    if debug:
        console.print("[dim]ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰: å‡¦ç†çŠ¶æ³ã‚’è¡¨ç¤ºã—ã¾ã™[/dim]")
    console.print()

    audio_chunks_received = 0
    last_debug_time = time.time()

    try:
        with audio_capture:
            with Live(display.render(), console=console, refresh_per_second=4) as live:
                while running:
                    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    audio = audio_capture.get_audio(timeout=0.1)

                    if audio is not None and len(audio) > 0:
                        audio_chunks_received += 1

                        # ãƒ‡ãƒãƒƒã‚°: éŸ³å£°ãƒ¬ãƒ™ãƒ«è¡¨ç¤º
                        if debug and time.time() - last_debug_time > 1.0:
                            rms = np.sqrt(np.mean(audio ** 2))
                            buffer_dur = engine.get_buffer_duration()
                            console.print(
                                f"[dim]éŸ³å£°ãƒ¬ãƒ™ãƒ«: {rms:.4f} | "
                                f"ãƒãƒƒãƒ•ã‚¡: {buffer_dur:.1f}s / {length/1000:.1f}s | "
                                f"ãƒãƒ£ãƒ³ã‚¯: {audio_chunks_received}[/dim]"
                            )
                            last_debug_time = time.time()

                        # VADãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                        if vad_filter and vad_filter.enabled:
                            if not vad_filter.is_speech(audio):
                                if debug:
                                    pass  # ç„¡éŸ³ã‚¹ã‚­ãƒƒãƒ—
                                continue

                        # è©±è€…åˆ†é›¢
                        if speaker and diarizer:
                            diarizer.process_audio(audio)

                        # Whisperã‚¨ãƒ³ã‚¸ãƒ³ã«ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
                        engine.add_audio(audio)

                        # ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒæºœã¾ã£ãŸã‚‰å‡¦ç†
                        buffer_duration = engine.get_buffer_duration()
                        if buffer_duration >= length / 1000:
                            if debug:
                                console.print(f"[dim]â†’ æ–‡å­—èµ·ã“ã—å®Ÿè¡Œä¸­... ({buffer_duration:.1f}s)[/dim]")
                            engine.process_realtime()

                    # è¡¨ç¤ºæ›´æ–°
                    live.update(display.render())

                # æœ€çµ‚å‡¦ç†
                final = engine.finalize()
                if final:
                    display.update(final.text, is_partial=False)
                    live.update(display.render())

    except Exception as e:
        console.print(f"[red]ã‚¨ãƒ©ãƒ¼: {e}[/red]")
        import traceback
        traceback.print_exc()

    # çµæœå‡ºåŠ›
    full_text = display.get_full_text()

    if output:
        output_path = Path(output)
        output_path.write_text(full_text, encoding="utf-8")
        console.print(f"\n[green]å‡ºåŠ›ä¿å­˜: {output_path}[/green]")

    console.print("\n[bold]æ–‡å­—èµ·ã“ã—çµæœ:[/bold]")
    console.print(Panel(full_text or "(ãªã—)", border_style="green"))


@cli.command()
@click.option(
    "--model", "-m",
    type=click.Choice([m.value for m in WhisperModel]),
    default="base",
    help="ä½¿ç”¨ã™ã‚‹Whisperãƒ¢ãƒ‡ãƒ«",
)
@click.option(
    "--language", "-l",
    default="ja",
    help="è¨€èªã‚³ãƒ¼ãƒ‰",
)
@click.option(
    "--device", "-d",
    type=int,
    help="ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹ID",
)
def stream(model: str, language: str, device: Optional[int]):
    """
    whisper.cpp stream ã‚’ä½¿ç”¨ã—ãŸã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ–‡å­—èµ·ã“ã—
    (whisper.cpp ã® stream ãƒã‚¤ãƒŠãƒªãŒå¿…è¦)
    """

    whisper_model = WhisperModel(model)
    config = WhisperConfig(model=whisper_model, language=language)

    display = RealtimeDisplay()

    def on_text(text: str, is_partial: bool):
        display.update(text, is_partial=is_partial)

    console.print("[green]ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹... (Ctrl+C ã§çµ‚äº†)[/green]\n")

    try:
        engine = StreamingWhisperEngine(config)
        engine.set_callback(on_text)

        with Live(display.render(), console=console, refresh_per_second=4) as live:
            engine.start(capture_id=device)

            while engine.is_running:
                time.sleep(0.1)
                live.update(display.render())

    except FileNotFoundError as e:
        console.print(f"[red]ã‚¨ãƒ©ãƒ¼: {e}[/red]")
        console.print("\n[yellow]whisper.cpp ã® stream ãƒã‚¤ãƒŠãƒªã‚’ãƒ“ãƒ«ãƒ‰ã—ã¦ãã ã•ã„[/yellow]")
    except KeyboardInterrupt:
        pass

    console.print("\n[bold]çµæœ:[/bold]")
    console.print(display.get_full_text())


def main():
    """ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    cli()


if __name__ == "__main__":
    main()
